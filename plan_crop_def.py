from global_ import *from my_def import *from batchgenerators.utilities.file_and_folder_operations import *import numpy as npfrom multiprocessing import Poolimport SimpleITK as sitkimport nibabel as nibimport shutilfrom collections import OrderedDict# 3. 检查数据完整def verify_same_geometry(img_1: sitk.Image, img_2: sitk.Image):    # 检查一下他们原点、像素间隔、方向、尺寸一致    ori1, spacing1, direction1, size1 = img_1.GetOrigin(), img_1.GetSpacing(), img_1.GetDirection(), img_1.GetSize()    ori2, spacing2, direction2, size2 = img_2.GetOrigin(), img_2.GetSpacing(), img_2.GetDirection(), img_2.GetSize()    # 原点、像素间隔、方向、尺寸差不多则True，否则False    same_ori = np.all(np.isclose(ori1, ori2))    if not same_ori:        print("the origin does not match between the images:")        print(ori1)        print(ori2)    same_spac = np.all(np.isclose(spacing1, spacing2))    if not same_spac:        print("the spacing does not match between the images")        print(spacing1)        print(spacing2)    same_dir = np.all(np.isclose(direction1, direction2))    if not same_dir:        print("the direction does not match between the images")        print(direction1)        print(direction2)    same_size = np.all(np.isclose(size1, size2))    if not same_size:        print("the size does not match between the images")        print(size1)        print(size2)    if same_ori and same_spac and same_dir and same_size:        return True    else:        return Falsedef verify_contains_only_expected_labels(itk_img: str, valid_labels: (tuple, list)):    img_npy = sitk.GetArrayFromImage(sitk.ReadImage(itk_img))    uniques = np.unique(img_npy)    invalid_uniques = [i for i in uniques if i not in valid_labels]    if len(invalid_uniques) == 0:        r = True    else:        r = False    # 一致r为True，不一致r为False且打印不一致的标签    return r, invalid_uniquesdef verify_all_same_orientation(folder):    """    这应该在裁剪后运行？？    """    # [图name]    nii_files = subfiles(folder, suffix=".nii.gz", join=True)    # 读图，通过仿射（4*4）取轴向    orientations = []    for n in nii_files:        # 读图        img = nib.load(n)        # 仿射（4*4）        affine = img.affine        # 轴向（'L', 'P', 'S'）        orientation = nib.aff2axcodes(affine)        orientations.append(orientation)    # 现在我们需要检查它们是否都一样    # 轴向一致（唯一）    orientations = np.array(orientations)    unique_orientations = np.unique(orientations, axis=0)    # 唯一则True，返回所有轴向    all_same = len(unique_orientations) == 1    return all_same, unique_orientationsdef verify_dataset_integrity(folder):    """    检查数据完整性，要求folder下有imagesTr、imagesTs、labelsTr，还需要有dataset.json    """    assert (Path(folder)/"dataset.json").is_file(), "%s下要dataset.json文件" % folder    assert (Path(folder)/"imagesTr").is_dir(), "%s下要imagesTr文件夹" % folder    assert (Path(folder)/"labelsTr").is_dir(), "%s下要labelsTr文件夹" % folder    # 加载json    dataset = load_json(join(folder, "dataset.json"))    # 取出训练文件/标签的绝对地址    training_cases = dataset['training']    # 单模态ct    num_modalities = len(dataset['modality'].keys())    # 测试集图    test_cases = dataset['test']    # 取训练集图名（不带后缀）(这里Path.stem不好用）    expected_train_identifiers = [i['image'].split("/")[-1][:-7] for i in training_cases]    # 取测试集图名    expected_test_identifiers = [i.split("/")[-1][:-7] for i in test_cases]    # 返回训练集图/标签的'.nii.gz'后缀的文件名    nii_files_in_imagesTr_ad = sorted([i for i in Path(Path(folder)/"imagesTr").glob('*.nii.gz') if i.is_file()])    nii_files_in_labelsTr_ad = sorted([i for i in Path(Path(folder)/"labelsTr").glob('*.nii.gz') if i.is_file()])    nii_files_in_imagesTr = [str(i.name) for i in nii_files_in_imagesTr_ad]    nii_files_in_labelsTr = [str(i.name) for i in nii_files_in_labelsTr_ad]    #  预设几何形状ok    label_files = []    geometries_OK = True    has_nan = False    # 检查所有图的唯一性    if len(expected_train_identifiers) != len(np.unique(expected_train_identifiers)): raise RuntimeError(" dataset.json 中有重复案例")    print("验证训练集")    # 取出所有训练集图名（不带后缀）    for c in expected_train_identifiers:        print("checking case", c)        # 检查是否所有文件都存在（根据json检查文件）        # 预期label文件的绝对地址放入label_files，对应预期image文件为加_0000        # label绝对地址        expected_label_file = join(folder, "labelsTr", c + ".nii.gz")        # label绝对地址进label_files表        label_files.append(expected_label_file)        # 对应image绝对地址(每个模态都要的喔）        expected_image_files = [join(folder, "imagesTr", c + "_%04.0d.nii.gz" % i) for i in range(num_modalities)]        # 检查有没有label绝对地址文件        assert isfile(expected_label_file), "could not find label file for case %s. Expected file: \n%s" % (            c, expected_label_file)        # 检查有没有image绝对文件地址（这里为什么要all()？答：所有模态）        assert all([isfile(i) for i in                    expected_image_files]), "some image files are missing for case %s. Expected files:\n %s" % (            c, expected_image_files)        # 验证所有模态的标签是否具有相同size。        # label读图        label_itk = sitk.ReadImage(expected_label_file)        # label有空值吗        nans_in_seg = np.any(np.isnan(sitk.GetArrayFromImage(label_itk)))        # 取label空值合集        has_nan = has_nan | nans_in_seg        # 如果有nan打印        if nans_in_seg:            print("分割标签中有NAN值 %s" % expected_label_file)        # image读图        images_itk = [sitk.ReadImage(i) for i in expected_image_files]        # 枚举图片（不同模态）        for i, img in enumerate(images_itk):            # image有空值吗            nans_in_image = np.any(np.isnan(sitk.GetArrayFromImage(img)))            # 取image空值合集            has_nan = has_nan | nans_in_image            # 验证图和label几何形状相同            same_geometry = verify_same_geometry(img, label_itk)            # 如果尺寸不一致则报错            if not same_geometry:                geometries_OK = False                print("图 %s 的图 / 标签 尺寸不一致" % expected_image_files[0][:-12])            if nans_in_image:                print("图中有NAN值 %s" % expected_image_files[i])        # 现在从列表 nii_files_in_imagesTr 和 nii_files_in_labelsTr 中删除经过筛选的文件（还没筛选完啊）        for i in expected_image_files:            nii_files_in_imagesTr.remove(os.path.basename(i))        nii_files_in_labelsTr.remove(os.path.basename(expected_label_file))    # 检查掉队者    # 过完所有图以后，该处理了吧    # 未包含在json里边的样本报错    assert len(        nii_files_in_imagesTr) == 0, "there are training cases in imagesTr that are not listed in dataset.json: %s" % nii_files_in_imagesTr    assert len(        nii_files_in_labelsTr) == 0, "there are training cases in labelsTr that are not listed in dataset.json: %s" % nii_files_in_labelsTr    # 验证标签中是否仅存在正确声明的值    print("验证标签值")    # 标签有几个类别，如[0, 1]    expected_labels = list(int(i) for i in dataset['labels'].keys())    expected_labels.sort()    # 检查标签是否连续    assert expected_labels[0] == 0, '第一个标签必须为 0 并映射到背景0'    # 验证连续差分全部为1    labels_valid_consecutive = np.ediff1d(expected_labels) == 1    assert all(labels_valid_consecutive), f'标签必须是连续的（0, 1, 2, ...） {np.array(expected_labels)[1:][~labels_valid_consecutive]} 不满足这个限制'    # 多线程*2 （检查标签内label类与json的label类是否对应） zip（label的预期绝对地址，标签类list）    p = Pool(default_num_threads)    results = p.starmap(verify_contains_only_expected_labels, zip(label_files, [expected_labels] * len(label_files)))    p.close()    p.join()    fail = False    print("预期的标签值为", expected_labels)    for i, r in enumerate(results):        # 如果不一致打印报错，r[1]为不一致的label类        if not r[0]:            print("在文件 %s 中发现了意外的标签。 找到了这些意想不到的值（它们不应该存在） %s" % (label_files[i], r[1]))            fail = True    # 类别不满足直接停了好吧，不然就是ok    if fail:        raise AssertionError(            "在训练数据集中发现了意外的标签。 请更正或相应调整您的 dataset.json")    else:        print("Labels OK")    # 检查测试集，但前提是实际上有一个测试集    if len(expected_test_identifiers) > 0:        print("Verifying test set")        nii_files_in_imagesTs_ad = sorted([i for i in Path(Path(folder) / "imagesTs").glob('*.nii.gz') if i.is_file()])        nii_files_in_imagesTs = [str(i.name) for i in nii_files_in_imagesTs_ad]        for c in expected_test_identifiers:            # 检查是否所有文件都存在            expected_image_files = [join(folder, "imagesTs", c + "_%04.0d.nii.gz" % i) for i in range(num_modalities)]            assert all([isfile(i) for i in                        expected_image_files]), "样本 %s 缺少一些图像文件。 预期文件:\n %s" % (                c, expected_image_files)            # 验证所有模态和标签具有相同的几何形状。            if num_modalities > 1:                images_itk = [sitk.ReadImage(i) for i in expected_image_files]                reference_img = images_itk[0]                for i, img in enumerate(images_itk[1:]):                    assert verify_same_geometry(img, reference_img), "图像 %s 的多模态size不一致。" % (                                                                         expected_image_files[i])            # 现在从列表 nii_files_in_imagesTs中删除选中的文件            for i in expected_image_files:                nii_files_in_imagesTs.remove(os.path.basename(i))        assert len(            nii_files_in_imagesTs) == 0, "在 dataset.json 中未列出的 imagesTs 中有训练案例：%s" % nii_files_in_imagesTr    # 验证所有的轴顺序是否相同    # 将唯一方向保存到 dataset.json    all_same, unique_orientations = verify_all_same_orientation(join(folder, "imagesTr"))    if not all_same:        print("警告：并非数据集中的所有图像都具有相同的轴顺序。 我们强烈建议您通过重新定向数据来纠正该问题。 fslreorient2std 应该可以解决问题")    # size一致    if not geometries_OK:        raise Warning("发现几何不匹配！ 检查文本输出！此时这不会导致错误，但您绝对应该检查您的几何形状是否正确!")    else:        print("Dataset OK")    # 存在空值的图和label    if has_nan:        raise RuntimeError("一些图像中有 nan 值。 这会破坏训练。 请参阅上面的文本输出以查看哪些")# 2. 取得id唯一项目# 已替换为my_def.may_i()def convert_id_to_task_name(task_id: int):    #    # Task005    startswith = "Task%03.0d" % task_id    # 取 raw 的 Task    candidates_raw = subdirs(nnUNet_raw_data, prefix=startswith, join=False)    unique_candidates = may_i(candidates_raw)    # 处理不同任务同一编号 （我已在限制起名处处理）    if len(unique_candidates) > 1:        raise RuntimeError("More than one task name found for task id %d. Please correct that. (I looked in the "                           "following folders:\n%s\n%s\n%s" % (task_id, nnUNet_raw_data, nnUNet_preprocessed,                                                               nnUNet_cropped_data))    if len(unique_candidates) == 0:        raise RuntimeError("Could not find a task with the ID %d. Make sure the requested task ID exists and that "                           "nnU-Net knows where raw and preprocessed data are located (see Documentation - "                           "Installation). Here are your currently defined folders:\nnnUNet_preprocessed=%s\nRESULTS_"                           "FOLDER=%s\nnnUNet_raw_data_base=%s\nIf something is not right, adapt your environemnt "                           "variables." %                           (task_id,                            os.environ.get('nnUNet_preprocessed') if os.environ.get('nnUNet_preprocessed') is not None else 'None',                            os.environ.get('RESULTS_FOLDER') if os.environ.get('RESULTS_FOLDER') is not None else 'None',                            os.environ.get('nnUNet_raw_data_base') if os.environ.get('nnUNet_raw_data_base') is not None else 'None',                            ))    return unique_candidates[0]# 4. crop裁def create_lists_from_splitted_dataset(base_folder_splitted):    lists = []    # 取得这个task的json    json_file = join(base_folder_splitted, "dataset.json")    # 打开，读取训练图列表    with open(json_file) as jsn:        d = json.load(jsn)        training_files = d['training']    # 几模态    num_modalities = len(d['modality'].keys())    # 训练文件    for tr in training_files:        cur_pat = []        # cut_pat加各模态的图        for mod in range(num_modalities):            cur_pat.append(join(base_folder_splitted, "imagesTr", tr['image'].split("/")[-1][:-7] +                                "_%04.0d.nii.gz" % mod))        # cut_pat加label        cur_pat.append(join(base_folder_splitted, "labelsTr", tr['label'].split("/")[-1]))        # 总列表【【单图模态0，单图模态1，label】，】        lists.append(cur_pat)    # 返回列表，{模态编号0：模态名，}    return lists, {int(i): d['modality'][str(i)] for i in d['modality'].keys()}def create_nonzero_mask(data):    from scipy.ndimage import binary_fill_holes # 填补空洞    assert len(data.shape) == 4 or len(data.shape) == 3, "data must have shape (C,data must have shape (C, X, Y, Z) or shape (C, X, Y)"    # 空mask ( X, Y, Z) or (X, Y)    nonzero_mask = np.zeros(data.shape[1:], dtype=bool)    for c in range(data.shape[0]):  # C        this_mask = data[c] != 0  # 图非零通道（模态）        # nonzero_mask：非0点为True        nonzero_mask = nonzero_mask | this_mask  # ‘或’  非0点为True    nonzero_mask = binary_fill_holes(nonzero_mask)  # 填补空洞    return nonzero_maskdef get_bbox_from_mask(mask, outside_value=0):    # 找zxy？轴中非零的最小及最大，画框裁剪    mask_voxel_coords = np.where(mask != outside_value)    minzidx = int(np.min(mask_voxel_coords[0]))    maxzidx = int(np.max(mask_voxel_coords[0])) + 1    minxidx = int(np.min(mask_voxel_coords[1]))    maxxidx = int(np.max(mask_voxel_coords[1])) + 1    minyidx = int(np.min(mask_voxel_coords[2]))    maxyidx = int(np.max(mask_voxel_coords[2])) + 1    return [[minzidx, maxzidx], [minxidx, maxxidx], [minyidx, maxyidx]]def crop_to_bbox(image, bbox):    assert len(image.shape) == 3, "only supports 3d images"    resizer = (slice(bbox[0][0], bbox[0][1]), slice(bbox[1][0], bbox[1][1]), slice(bbox[2][0], bbox[2][1]))    return image[resizer]def crop_to_nonzero(data, seg=None, nonzero_label=-1):    """    裁剪为非零（注意：        # print('data.shape',data.shape) → (1, 39, 512, 512)        # print('seg        ',seg.shape) → (1, 39, 512, 512)    :param nonzero_label: 这将被写入分割图中    :return:    """    # print('1 data.shape',data.shape) → (1, 39, 512, 512)    # nonzero_mask：非0点为True（非0 图 mask）    nonzero_mask = create_nonzero_mask(data)    # print('2 nonzero_mask.shape',nonzero_mask.shape) → (39, 512, 512)    # 非0 图 mask的边界（以此边界为准）    bbox = get_bbox_from_mask(nonzero_mask, 0)    # print('3 bbox', bbox)  # 裁剪的边缘列表 → 3 bbox [[0, 39], [0, 512], [0, 512]]    cropped_data = []    # 图 的裁剪 加维 cat    for c in range(data.shape[0]):  # C        cropped = crop_to_bbox(data[c], bbox)  # 根据box裁        cropped_data.append(cropped[None])  # 加0维    data = np.vstack(cropped_data)  # cat    # 标签 的裁剪 加维 cat    if seg is not None:  # 标签同        cropped_seg = []        for c in range(seg.shape[0]):  # C            cropped = crop_to_bbox(seg[c], bbox)  # 根据box裁            cropped_seg.append(cropped[None])  # 加0维        seg = np.vstack(cropped_seg)  # cat    # print('4 data.shape', data.shape) → (1, 39, 512, 512)    # print('5 seg', seg.shape) → (1, 39, 512, 512)    # print('6 nonzero_mask.shape', nonzero_mask.shape) → (39, 512, 512)    # 非0 图 mask的裁剪 加维 cat    nonzero_mask = crop_to_bbox(nonzero_mask, bbox)[None]    # print('7 nonzero_mask.shape',nonzero_mask.shape) →  (1, 39, 512, 512)    if seg is not None:        # 如果要seg，标签为0（背景）且 图非0（nonzero_mask == 0/False）  时取-1        seg[(seg == 0) & (nonzero_mask == 0)] = nonzero_label  # ‘与’同时达成    else:        # 如果不seg，非0 图 mask取值化        nonzero_mask = nonzero_mask.astype(int)        # 为0 的取-1，为1的取0，与上逻辑相同，即（前景为1，背景为0或-1，其中0为0值背景，-1为非0值背景）        nonzero_mask[nonzero_mask == 0] = nonzero_label        nonzero_mask[nonzero_mask > 0] = 0        seg = nonzero_mask    # 意思是没有标签的话，就没前景，只分-1和0呗    # 返回 多模态图，label（前景为1，背景为0或-1，其中0为0值背景，-1为非0值背景），box裁剪边界列表    return data, seg, bboxdef load_case_from_list_of_files(data_files, seg_file=None):    # 这里的data_files多模态的话就是列表内多个地址了    # print('data_files',data_files) →data_files ['nnUNet_raw_data/Task001_Try/imagesTr/1000_V_5mm_0000.nii.gz']    # print('seg_file',seg_file) → nnUNet_raw_data/Task001_Try/labelsTr/1000_V_5mm.nii.gz    assert isinstance(data_files, list) or isinstance(data_files, tuple), "case 必须是列表或元组"    # 搞个字典    properties = OrderedDict()    # 读的图和标签    data_itk = [sitk.ReadImage(f) for f in data_files]    # 原始数据的size、spacing、文件列表、分割文件（原来是zyx）    properties["original_size_of_raw_data"] = np.array(data_itk[0].GetSize())[[2, 1, 0]]    properties["original_spacing"] = np.array(data_itk[0].GetSpacing())[[2, 1, 0]]    properties["list_of_data_files"] = data_files    properties["seg_file"] = seg_file    # itk读的图的中心点、spacing、轴向（现在是xyz）    properties["itk_origin"] = data_itk[0].GetOrigin()    properties["itk_spacing"] = data_itk[0].GetSpacing()    properties["itk_direction"] = data_itk[0].GetDirection()    # 图升维（图[None]表示0维增加了一个维度）    # 多模态的话，在维度0 cat 所有模态    data_npy = np.vstack([sitk.GetArrayFromImage(d)[None] for d in data_itk])    # print('位置1',sitk.GetArrayFromImage(data_itk[0]).shape) → 位置1 (35, 512, 512)    # print('位置2',sitk.GetArrayFromImage(data_itk[0])[None].shape) → 位置2 (1, 35, 512, 512)    if seg_file is not None:        seg_itk = sitk.ReadImage(seg_file)        # label升维（标签[None]表示0维增加了一个维度）        seg_npy = sitk.GetArrayFromImage(seg_itk)[None].astype(np.float32)    else:        seg_npy = None    return data_npy.astype(np.float32), seg_npy, propertiesdef get_case_identifier(case):    case_identifier = case[0].split("/")[-1].split(".nii.gz")[0][:-5]    return case_identifierclass ImageCropper(object):    def __init__(self, num_threads, output_folder=None):        """        裁剪有值区域，一般 BRaTS 和 ISLES 图像会显着减小，其他不会        :param num_threads:        :param output_folder: whete to store the cropped data        :param list_of_files:        """        self.output_folder = output_folder        self.num_threads = num_threads        if self.output_folder is not None:            maybe_mkdir_p(self.output_folder)    @staticmethod    # crop（垂直方向堆叠，分割图，图信息字典）    def crop(data, properties, seg=None):        # print('data.shape',data.shape) → (1, 39, 512, 512)        # print('seg',seg.shape) → seg (1, 39, 512, 512)        # print('properties',properties) → OrderedDict([        # ('zyx的原图size',array([ 39, 512, 512])),        # ('zyx的原图spacing', array([5.        , 0.68359399, 0.68359399])),        # ('zyx的原图绝对地址', ['nnUNet_raw_data/Task001_Try/imagesTr/1003_V_5mm_0000.nii.gz']),        # ('zyx的原label绝对地址', 'nnUNet_raw_data/Task001_Try/labelsTr/1003_V_5mm.nii.gz'),        # ('xyz的原点', (-160.8000030517578, -175.0, -209.25)),        # ('xyz的spacing', (0.6835939884185791, 0.6835939884185791, 5.0)),        # ('xyz的轴向', (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0))])        shape_before = data.shape        # 多模态图（box裁剪后），分割label（box裁剪后，无标签/标签处理），box裁剪边界列表        #        data, seg, bbox = crop_to_nonzero(data, seg, nonzero_label=-1)        shape_after = data.shape        print("before crop:", shape_before, "after crop:", shape_after, "spacing:",              np.array(properties["original_spacing"]), "\n")        # 补充 图信息字典        properties["crop_bbox"] = bbox        # 类别， [-1.  0.  1.] 其中0为背景，-1为非0背景，1为前景        properties['classes'] = np.unique(seg)        # print('8 np.unique(seg)', np.unique(seg)) → [-1.  0.  1.]        seg[seg < -1] = 0        properties["size_after_cropping"] = data[0].shape        return data, seg, properties    @staticmethod    # 从文件列表中切图和标签(【图绝对地址】，标签绝对地址）    def crop_from_list_of_files(data_files, seg_file=None):        # print('data_files',data_files) →data_files ['nnUNet_raw_data/Task001_Try/imagesTr/1000_V_5mm_0000.nii.gz']        # print('seg_file',seg_file) → nnUNet_raw_data/Task001_Try/labelsTr/1000_V_5mm.nii.gz        data, seg, properties = load_case_from_list_of_files(data_files, seg_file)        # print('data.shape',data.shape , properties)        # print('seg',seg.shape , properties)        # print('data.shape',data.shape) → (1, 39, 512, 512)        # print('seg        ',seg.shape) → (1, 39, 512, 512)        # print('properties',properties) → OrderedDict([        # ('zyx的原图size',array([ 39, 512, 512])),        # ('zyx的原图spacing', array([5.        , 0.68359399, 0.68359399])),        # ('zyx的原图绝对地址', ['nnUNet_raw_data/Task001_Try/imagesTr/1003_V_5mm_0000.nii.gz']),        # ('zyx的原label绝对地址', 'nnUNet_raw_data/Task001_Try/labelsTr/1003_V_5mm.nii.gz'),        # ('xyz的原点', (-160.8000030517578, -175.0, -209.25)),        # ('xyz的spacing', (0.6835939884185791, 0.6835939884185791, 5.0)),        # ('xyz的轴向', (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0))])        return ImageCropper.crop(data, properties, seg)    # 加载切图保存？（【图/标签的绝对地址】，图名，覆盖）    def load_crop_save(self, case, case_identifier, overwrite_existing=False):        # 试试打印图名，阔以        try:            # print('case',case)            # ['nnUNet_raw_data/Task001_Try/imagesTr/1000_V_5mm_0000.nii.gz', 'nnUNet_raw_data/Task001_Try/labelsTr/1000_V_5mm.nii.gz']            # 如果覆盖或者没有npz/pkl文件            if overwrite_existing \                    or (not os.path.isfile(os.path.join(self.output_folder, "%s.npz" % case_identifier))                        or not os.path.isfile(os.path.join(self.output_folder, "%s.pkl" % case_identifier))):                #                # case[:-1] ['nnUNet_raw_data/Task001_Try/imagesTr/1000_V_5mm_0000.nii.gz']                # case[-1]    nnUNet_raw_data/Task001_Try/labelsTr/1000_V_5mm.nii.gz                data, seg, properties = self.crop_from_list_of_files(case[:-1], case[-1])                all_data = np.vstack((data, seg))                np.savez_compressed(os.path.join(self.output_folder, "%s.npz" % case_identifier), data=all_data)                with open(os.path.join(self.output_folder, "%s.pkl" % case_identifier), 'wb') as f:                    pickle.dump(properties, f)        # 例外报错        except Exception as e:            print("Exception in", case_identifier, ":")            print(e)            raise e    def get_list_of_cropped_files(self):        return subfiles(self.output_folder, join=True, suffix=".npz")    def get_patient_identifiers_from_cropped_files(self):        return [i.split("/")[-1][:-4] for i in self.get_list_of_cropped_files()]    def run_cropping(self, list_of_files, overwrite_existing=False, output_folder=None):        """        将真实标签nifti分割复制到预处理文件夹中，以便我们可以使用它们进行评估        :param list_of_files: 文件列表列表 [[PATIENTID_TIMESTEP_0000.nii.gz],] 或[[图，label的绝对地址],]        :param overwrite_existing:        :param output_folder:        :return:        """        # 输出位置可改        if output_folder is not None:            self.output_folder = output_folder        # 真实标签分割后放这        output_folder_gt = os.path.join(self.output_folder, "gt_segmentations")        maybe_mkdir_p(output_folder_gt)        # 文件列表（【【image，label】，】）枚举        for j, case in enumerate(list_of_files):            # label非空则复制            # case = [图，label]            if case[-1] is not None:                shutil.copy(case[-1], output_folder_gt)        list_of_args = []        for j, case in enumerate(list_of_files):            # 图名（不加_0000的）            case_identifier = get_case_identifier(case)            # （图/标签的绝对地址，图名，覆盖）            list_of_args.append((case, case_identifier, overwrite_existing))        p = Pool(self.num_threads)        # load_crop_save(图绝对地址，图名，覆盖)        p.starmap(self.load_crop_save, list_of_args)        p.close()        p.join()    def load_properties(self, case_identifier):        with open(os.path.join(self.output_folder, "%s.pkl" % case_identifier), 'rb') as f:            properties = pickle.load(f)        return properties    def save_properties(self, case_identifier, properties):        with open(os.path.join(self.output_folder, "%s.pkl" % case_identifier), 'wb') as f:            pickle.dump(properties, f)def crop(task_string, override=False, num_threads=default_num_threads):    # 输出到这    cropped_out_dir = join(nnUNet_cropped_data, task_string)    Path(cropped_out_dir).mkdir(exist_ok=True, parents=True)    # 如果覆盖，递归删除并建空文件夹    if override and Path(cropped_out_dir).is_dir():        shutil.rmtree(cropped_out_dir)        maybe_mkdir_p(cropped_out_dir)    # 从这取，每个模态的图名列表    splitted_4d_output_dir_task = join(nnUNet_raw_data, task_string)    # list里边就放的所有模态所有[[图/标签的绝对地址],]    lists, _ = create_lists_from_splitted_dataset(splitted_4d_output_dir_task)    # 切图（线程，切后输出文件夹）    imgcrop = ImageCropper(num_threads, cropped_out_dir)    imgcrop.run_cropping(lists, overwrite_existing=override)    # 复制json过去    shutil.copy(join(nnUNet_raw_data, task_string, "dataset.json"), cropped_out_dir)# 数据指纹/分析import picklefrom skimage.morphology import label# 从裁剪文件中获取患者标识符def get_patient_identifiers_from_cropped_files(folder):    return [i.split("/")[-1][:-4] for i in subfiles(folder, join=True, suffix=".npz")]class DatasetAnalyzer(object):    def __init__(self, folder_with_cropped_data, overwrite=True, num_processes=default_num_threads):        """        :param folder_with_cropped_data:裁减好的数据文件夹        :param overwrite: 覆盖：如果为真，则从数据中重新计算。默认值为 True。        """        self.num_processes = num_processes  # 进程数        self.overwrite = overwrite  # 覆盖        self.folder_with_cropped_data = folder_with_cropped_data  # 裁减好的数据文件夹        self.sizes = self.spacings = None  # 尺寸和像素间隔会改        self.patient_identifiers = get_patient_identifiers_from_cropped_files(self.folder_with_cropped_data)  # 图名列表        assert isfile(join(self.folder_with_cropped_data, "dataset.json")), \            "dataset.json needs to be in folder_with_cropped_data"  # 里边要有json文件        self.props_per_case_file = join(self.folder_with_cropped_data, "props_per_case.pkl")  # ？        self.intensityproperties_file = join(self.folder_with_cropped_data, "intensityproperties.pkl")  # ？    # 加载pkl（相关信息）    def load_properties_of_cropped(self, case_identifier):        with open(join(self.folder_with_cropped_data, "%s.pkl" % case_identifier), 'rb') as f:            properties = pickle.load(f)        return properties    @staticmethod    def _check_if_all_in_one_region(seg, regions):        res = OrderedDict()        for r in regions:            new_seg = np.zeros(seg.shape)            for c in r:                new_seg[seg == c] = 1            labelmap, numlabels = label(new_seg, return_num=True)            if numlabels != 1:                res[tuple(r)] = False            else:                res[tuple(r)] = True        return res    @staticmethod    def _collect_class_and_region_sizes(seg, all_classes, vol_per_voxel):        volume_per_class = OrderedDict()        region_volume_per_class = OrderedDict()        for c in all_classes:            region_volume_per_class[c] = []            volume_per_class[c] = np.sum(seg == c) * vol_per_voxel            labelmap, numregions = label(seg == c, return_num=True)            for l in range(1, numregions + 1):                region_volume_per_class[c].append(np.sum(labelmap == l) * vol_per_voxel)        return volume_per_class, region_volume_per_class    def _get_unique_labels(self, patient_identifier):        seg = np.load(join(self.folder_with_cropped_data, patient_identifier) + ".npz")['data'][-1]        unique_classes = np.unique(seg)        return unique_classes    def _load_seg_analyze_classes(self, patient_identifier, all_classes):        """        1) what class is in this training case?        2) what is the size distribution for each class?        3) what is the region size of each class?        4) check if all in one region        :return:        """        seg = np.load(join(self.folder_with_cropped_data, patient_identifier) + ".npz")['data'][-1]        pkl = load_pickle(join(self.folder_with_cropped_data, patient_identifier) + ".pkl")        vol_per_voxel = np.prod(pkl['itk_spacing'])        # ad 1)        unique_classes = np.unique(seg)        # 4) check if all in one region        regions = list()        regions.append(list(all_classes))        for c in all_classes:            regions.append((c, ))        all_in_one_region = self._check_if_all_in_one_region(seg, regions)        # 2 & 3) region sizes        volume_per_class, region_sizes = self._collect_class_and_region_sizes(seg, all_classes, vol_per_voxel)        return unique_classes, all_in_one_region, volume_per_class, region_sizes    def get_classes(self):        datasetjson = load_json(join(self.folder_with_cropped_data, "dataset.json"))        return datasetjson['labels']    def analyse_segmentations(self):        class_dct = self.get_classes()        if self.overwrite or not isfile(self.props_per_case_file):            p = Pool(self.num_processes)            res = p.map(self._get_unique_labels, self.patient_identifiers)            p.close()            p.join()            props_per_patient = OrderedDict()            for p, unique_classes in \                            zip(self.patient_identifiers, res):                props = dict()                props['has_classes'] = unique_classes                props_per_patient[p] = props            save_pickle(props_per_patient, self.props_per_case_file)        else:            props_per_patient = load_pickle(self.props_per_case_file)        return class_dct, props_per_patient    def get_sizes_and_spacings_after_cropping(self):        sizes = []        spacings = []        # for c in case_identifiers:        for c in self.patient_identifiers:            # 加载pkl文件（具体信息）            properties = self.load_properties_of_cropped(c)            # 裁后size和原始像素间隔            sizes.append(properties["size_after_cropping"])            spacings.append(properties["original_spacing"])        return sizes, spacings    def get_modalities(self):        datasetjson = load_json(join(self.folder_with_cropped_data, "dataset.json"))        modalities = datasetjson["modality"]        modalities = {int(k): modalities[k] for k in modalities.keys()}        return modalities    # 通过裁剪来减小尺寸    def get_size_reduction_by_cropping(self):        # 字典{p：size变化比例}        size_reduction = OrderedDict()        # 每个图的 原始size/裁后size        for p in self.patient_identifiers:            props = self.load_properties_of_cropped(p)            shape_before_crop = props["original_size_of_raw_data"]            shape_after_crop = props['size_after_cropping']            size_red = np.prod(shape_after_crop) / np.prod(shape_before_crop)            size_reduction[p] = size_red        # {p：size变化比例}        return size_reduction    # 从前景中获取体素    def _get_voxels_in_foreground(self, patient_identifier, modality_id):        # 获取数据        all_data = np.load(join(self.folder_with_cropped_data, patient_identifier) + ".npz")['data']        # 获取模态（通过模态id）        modality = all_data[modality_id]        # label的前景        mask = all_data[-1] > 0        # 每隔10个取1个        voxels = list(modality[mask][::10])  # 无需获取每个体素        return voxels    @staticmethod    # 统计（中值、平均值、标准差、最小值、最大值、统计大值、统计小值）    def _compute_stats(voxels):        # 如果无前景，7个全nan        if len(voxels) == 0:            return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan        median = np.median(voxels)  # 中值        mean = np.mean(voxels)  # 平均值        sd = np.std(voxels)  # 标准差        mn = np.min(voxels)  # 最小值        mx = np.max(voxels)  # 最大值        percentile_99_5 = np.percentile(voxels, 99.5)  # 取列表中99.5%的数⼩于该数字        percentile_00_5 = np.percentile(voxels, 00.5)  # 取列表中 0.5%的数⼩于该数字        return median, mean, sd, mn, mx, percentile_99_5, percentile_00_5    # 收集强度属性（模态长度）    def collect_intensity_properties(self, num_modalities):        # 如果覆盖或者没有强度文件        if self.overwrite or not isfile(self.intensityproperties_file):            p = Pool(self.num_processes)            # 建立字典            results = OrderedDict()            # {key：每个模态id，value：}            for mod_id in range(num_modalities):                results[mod_id] = OrderedDict()                # 从前景中获取体素                v = p.starmap(self._get_voxels_in_foreground, zip(self.patient_identifiers,                                                              [mod_id] * len(self.patient_identifiers)))                # v是打包的列表，iv是列表，w是所有列成一个表                w = []                for iv in v:                    w += iv                # 总统计（中值、平均值、标准差、最小值、最大值、统计大值、统计小值）                median, mean, sd, mn, mx, percentile_99_5, percentile_00_5 = self._compute_stats(w)                # 单图统计（中值、平均值、标准差、最小值、最大值、统计大值、统计小值）列表  [(七值), ]                local_props = p.map(self._compute_stats, v)                # 小字典{[图名][信息]：值，}                props_per_case = OrderedDict()                for i, pat in enumerate(self.patient_identifiers):                    props_per_case[pat] = OrderedDict()                    props_per_case[pat]['median'] = local_props[i][0]                    props_per_case[pat]['mean'] = local_props[i][1]                    props_per_case[pat]['sd'] = local_props[i][2]                    props_per_case[pat]['mn'] = local_props[i][3]                    props_per_case[pat]['mx'] = local_props[i][4]                    props_per_case[pat]['percentile_99_5'] = local_props[i][5]                    props_per_case[pat]['percentile_00_5'] = local_props[i][6]                # 字典【模态id】【信息】                results[mod_id]['local_props'] = props_per_case                results[mod_id]['median'] = median                results[mod_id]['mean'] = mean                results[mod_id]['sd'] = sd                results[mod_id]['mn'] = mn                results[mod_id]['mx'] = mx                results[mod_id]['percentile_99_5'] = percentile_99_5                results[mod_id]['percentile_00_5'] = percentile_00_5            p.close()            p.join()            # 打包强度信息            save_pickle(results, self.intensityproperties_file)        else:            results = load_pickle(self.intensityproperties_file)        # 强度信息        return results    def analyze_dataset(self, collect_intensityproperties=True):        # 获取所有间距和尺寸（列表）        sizes, spacings = self.get_sizes_and_spacings_after_cropping()        # get all classes and what classes are in what patients        # class min size        # region size per class        # 获取所有类        classes = self.get_classes()        all_classes = [int(i) for i in classes.keys() if int(i) > 0]        # 所有模态        modalities = self.get_modalities()        # 收集强度信息（中值、平均值、标准差、最小值、最大值、统计大值、统计小值、单图统计）        if collect_intensityproperties:            intensityproperties = self.collect_intensity_properties(len(modalities))        else:            intensityproperties = None        # 通过裁剪减小尺寸（比例）{p：size变化比例}      OrderedDict([('1000_V_5mm', 1.0), ('1001_V_5mm', 1.0),])        size_reductions = self.get_size_reduction_by_cropping()        dataset_properties = dict()        dataset_properties['all_sizes'] = sizes        dataset_properties['all_spacings'] = spacings        dataset_properties['all_classes'] = all_classes        dataset_properties['modalities'] = modalities  # {idx: modality name}        dataset_properties['intensityproperties'] = intensityproperties  # 强度特性        dataset_properties['size_reductions'] = size_reductions  # {patient_id: size_reduction}        print("一个大表",dataset_properties)        # {'all_sizes':    [(35, 512, 512), (39, 512, 512), (54, 512, 512), (39, 512, 512), (34, 512, 512), (59, 512, 512), (59, 512, 512), (39, 512, 512), (49, 512, 512), (46, 512, 512)],        #  'all_spacings': [array([5.        , 0.68359399, 0.68359399]), array([5.        , 0.62890601, 0.62890601]), array([5.        , 0.68359399, 0.68359399]), array([5.        , 0.68359399, 0.68359399]), array([5.        , 0.68359399, 0.68359399]), array([5.        , 0.65820301, 0.65820301]), array([5.        , 0.68359399, 0.68359399]), array([5.        , 0.76367199, 0.76367199]), array([5.        , 0.76367199, 0.76367199]), array([5.        , 0.78320301, 0.78320301])],        #  'all_classes':  [1],        #  'modalities': {0: 'CT'},        #  'intensityproperties': OrderedDict([(0, OrderedDict([('local_props', OrderedDict([('1000_V_5mm', OrderedDict([('median', 116.0), ('mean', 113.53657), ('sd', 32.98306), ('mn', -100.0), ('mx', 233.0), ('percentile_99_5', 192.39999999999964), ('percentile_00_5', -1.0)])), ('1001_V_5mm', OrderedDict([('median', 131.0), ('mean', 130.43073), ('sd', 22.57967), ('mn', -29.0), ('mx', 230.0), ('percentile_99_5', 187.39999999999964), ('percentile_00_5', 60.0)])), ('1002_V_5mm', OrderedDict([('median', 135.0), ('mean', 134.1138), ('sd', 21.96225), ('mn', 2.0), ('mx', 214.0), ('percentile_99_5', 189.0), ('percentile_00_5', 65.0)])), ('1003_V_5mm', OrderedDict([('median', 89.0), ('mean', 87.88882), ('sd', 22.906015), ('mn', -46.0), ('mx', 215.0), ('percentile_99_5', 147.0), ('percentile_00_5', 21.0)])), ('1004_V_5mm', OrderedDict([('median', 130.0), ('mean', 127.827324), ('sd', 23.885273), ('mn', -50.0), ('mx', 224.0), ('percentile_99_5', 181.0), ('percentile_00_5', 22.945)])), ('1006_V_5mm', OrderedDict([('median', 151.0), ('mean', 150.86201), ('sd', 28.7337), ('mn', -24.0), ('mx', 297.0), ('percentile_99_5', 224.0), ('percentile_00_5', 67.0)])), ('1007_pizang_V_5mm', OrderedDict([('median', 156.0), ('mean', 155.43034), ('sd', 24.296597), ('mn', 13.0), ('mx', 284.0), ('percentile_99_5', 219.32500000000073), ('percentile_00_5', 79.675)])), ('1008_V_5mm', OrderedDict([('median', 102.0), ('mean', 100.43794), ('sd', 32.16819), ('mn', -62.0), ('mx', 210.0), ('percentile_99_5', 179.32000000000016), ('percentile_00_5', -5.0)])), ('1009_V_5mm', OrderedDict([('median', 97.0), ('mean', 96.7682), ('sd', 24.287102), ('mn', -14.0), ('mx', 205.0), ('percentile_99_5', 158.0), ('percentile_00_5', 32.0)])), ('1010_V_5mm', OrderedDict([('median', 96.0), ('mean', 95.76099), ('sd', 22.341742), ('mn', -49.0), ('mx', 179.0), ('percentile_99_5', 153.0), ('percentile_00_5', 33.0)]))])), ('median', 116.0), ('mean', 117.71689), ('sd', 36.133633), ('mn', -100.0), ('mx', 297.0), ('percentile_99_5', 208.0), ('percentile_00_5', 28.0)]))]), 'size_reductions': OrderedDict([('1000_V_5mm', 1.0), ('1001_V_5mm', 1.0), ('1002_V_5mm', 1.0), ('1003_V_5mm', 1.0), ('1004_V_5mm', 1.0), ('1006_V_5mm', 1.0), ('1007_pizang_V_5mm', 1.0), ('1008_V_5mm', 1.0), ('1009_V_5mm', 1.0), ('1010_V_5mm', 0.9787234042553191)])}        save_pickle(dataset_properties, join(self.folder_with_cropped_data, "dataset_properties.pkl"))        return dataset_properties# 制定训练计划from nnunet.configuration import default_num_threadsfrom nnunet.network_architecture.generic_UNet import Generic_UNetdefault_data_identifier = 'nnUNetData_plans_v2.1'from copy import deepcopyfrom nnunet.experiment_planning.common_utils import get_pool_and_conv_props_poolLateV2from nnunet.experiment_planning.utils import create_lists_from_splitted_datasetfrom nnunet.preprocessing.cropping import get_case_identifier_from_npzfrom nnunet.training.model_restore import recursive_find_python_classfrom copy import deepcopyfrom nnunet.experiment_planning.common_utils import get_pool_and_conv_propsfrom nnunet.paths import *class ExperimentPlanner(object):    def __init__(self, folder_with_cropped_data, preprocessed_output_folder):        self.folder_with_cropped_data = folder_with_cropped_data        self.preprocessed_output_folder = preprocessed_output_folder        self.list_of_cropped_npz_files = subfiles(self.folder_with_cropped_data, True, None, ".npz", True)        self.preprocessor_name = "GenericPreprocessor"        assert isfile(join(self.folder_with_cropped_data, "dataset_properties.pkl")), \            "folder_with_cropped_data must contain dataset_properties.pkl"        self.dataset_properties = load_pickle(join(self.folder_with_cropped_data, "dataset_properties.pkl"))        self.plans_per_stage = OrderedDict()        self.plans = OrderedDict()        self.plans_fname = join(self.preprocessed_output_folder, "nnUNetPlans" + "fixed_plans_3D.pkl")        self.data_identifier = default_data_identifier        self.transpose_forward = [0, 1, 2]        self.transpose_backward = [0, 1, 2]        self.unet_base_num_features = Generic_UNet.BASE_NUM_FEATURES_3D        self.unet_max_num_filters = 320        self.unet_max_numpool = 999        self.unet_min_batch_size = 2        self.unet_featuremap_min_edge_length = 4        self.target_spacing_percentile = 50        self.anisotropy_threshold = 3        self.how_much_of_a_patient_must_the_network_see_at_stage0 = 4  # 1/4 of a patient        self.batch_size_covers_max_percent_of_dataset = 0.05  # all samples in the batch together cannot cover more        # than 5% of the entire dataset        self.conv_per_stage = 2    def get_target_spacing(self):        spacings = self.dataset_properties['all_spacings']        # target = np.median(np.vstack(spacings), 0)        # if target spacing is very anisotropic we may want to not downsample the axis with the worst spacing        # uncomment after mystery task submission        """worst_spacing_axis = np.argmax(target)        if max(target) > (2.5 * min(target)):            spacings_of_that_axis = np.vstack(spacings)[:, worst_spacing_axis]            target_spacing_of_that_axis = np.percentile(spacings_of_that_axis, 5)            target[worst_spacing_axis] = target_spacing_of_that_axis"""        target = np.percentile(np.vstack(spacings), self.target_spacing_percentile, 0)        return target    def save_my_plans(self):        with open(self.plans_fname, 'wb') as f:            pickle.dump(self.plans, f)    def load_my_plans(self):        self.plans = load_pickle(self.plans_fname)        self.plans_per_stage = self.plans['plans_per_stage']        self.dataset_properties = self.plans['dataset_properties']        self.transpose_forward = self.plans['transpose_forward']        self.transpose_backward = self.plans['transpose_backward']    def determine_postprocessing(self):        pass        """        Spoiler: This is unused, postprocessing was removed. Ignore it.        :return:        print("determining postprocessing...")        props_per_patient = self.dataset_properties['segmentation_props_per_patient']        all_region_keys = [i for k in props_per_patient.keys() for i in props_per_patient[k]['only_one_region'].keys()]        all_region_keys = list(set(all_region_keys))        only_keep_largest_connected_component = OrderedDict()        for r in all_region_keys:            all_results = [props_per_patient[k]['only_one_region'][r] for k in props_per_patient.keys()]            only_keep_largest_connected_component[tuple(r)] = all(all_results)        print("Postprocessing: only_keep_largest_connected_component", only_keep_largest_connected_component)        all_classes = self.dataset_properties['all_classes']        classes = [i for i in all_classes if i > 0]        props_per_patient = self.dataset_properties['segmentation_props_per_patient']        min_size_per_class = OrderedDict()        for c in classes:            all_num_voxels = []            for k in props_per_patient.keys():                all_num_voxels.append(props_per_patient[k]['volume_per_class'][c])            if len(all_num_voxels) > 0:                min_size_per_class[c] = np.percentile(all_num_voxels, 1) * MIN_SIZE_PER_CLASS_FACTOR            else:                min_size_per_class[c] = np.inf        min_region_size_per_class = OrderedDict()        for c in classes:            region_sizes = [l for k in props_per_patient for l in props_per_patient[k]['region_volume_per_class'][c]]            if len(region_sizes) > 0:                min_region_size_per_class[c] = min(region_sizes)                # we don't need that line but better safe than sorry, right?                min_region_size_per_class[c] = min(min_region_size_per_class[c], min_size_per_class[c])            else:                min_region_size_per_class[c] = 0        print("Postprocessing: min_size_per_class", min_size_per_class)        print("Postprocessing: min_region_size_per_class", min_region_size_per_class)        return only_keep_largest_connected_component, min_size_per_class, min_region_size_per_class        """    def get_properties_for_stage(self, current_spacing, original_spacing, original_shape, num_cases,                                 num_modalities, num_classes):        """        Computation of input patch size starts out with the new median shape (in voxels) of a dataset. This is        opposed to prior experiments where I based it on the median size in mm. The rationale behind this is that        for some organ of interest the acquisition method will most likely be chosen such that the field of view and        voxel resolution go hand in hand to show the doctor what they need to see. This assumption may be violated        for some modalities with anisotropy (cine MRI) but we will have t live with that. In future experiments I        will try to 1) base input patch size match aspect ratio of input size in mm (instead of voxels) and 2) to        try to enforce that we see the same 'distance' in all directions (try to maintain equal size in mm of patch)        The patches created here attempt keep the aspect ratio of the new_median_shape        :param current_spacing:        :param original_spacing:        :param original_shape:        :param num_cases:        :return:        """        new_median_shape = np.round(original_spacing / current_spacing * original_shape).astype(int)        dataset_num_voxels = np.prod(new_median_shape) * num_cases        # the next line is what we had before as a default. The patch size had the same aspect ratio as the median shape of a patient. We swapped t        # input_patch_size = new_median_shape        # compute how many voxels are one mm        input_patch_size = 1 / np.array(current_spacing)        # normalize voxels per mm        input_patch_size /= input_patch_size.mean()        # create an isotropic patch of size 512x512x512mm        input_patch_size *= 1 / min(input_patch_size) * 512  # to get a starting value        input_patch_size = np.round(input_patch_size).astype(int)        # clip it to the median shape of the dataset because patches larger then that make not much sense        input_patch_size = [min(i, j) for i, j in zip(input_patch_size, new_median_shape)]        network_num_pool_per_axis, pool_op_kernel_sizes, conv_kernel_sizes, new_shp, \        shape_must_be_divisible_by = get_pool_and_conv_props_poolLateV2(input_patch_size,                                                                        self.unet_featuremap_min_edge_length,                                                                        self.unet_max_numpool,                                                                        current_spacing)        ref = Generic_UNet.use_this_for_batch_size_computation_3D        here = Generic_UNet.compute_approx_vram_consumption(new_shp, network_num_pool_per_axis,                                                            self.unet_base_num_features,                                                            self.unet_max_num_filters, num_modalities,                                                            num_classes,                                                            pool_op_kernel_sizes, conv_per_stage=self.conv_per_stage)        while here > ref:            axis_to_be_reduced = np.argsort(new_shp / new_median_shape)[-1]            tmp = deepcopy(new_shp)            tmp[axis_to_be_reduced] -= shape_must_be_divisible_by[axis_to_be_reduced]            _, _, _, _, shape_must_be_divisible_by_new = \                get_pool_and_conv_props_poolLateV2(tmp,                                                   self.unet_featuremap_min_edge_length,                                                   self.unet_max_numpool,                                                   current_spacing)            new_shp[axis_to_be_reduced] -= shape_must_be_divisible_by_new[axis_to_be_reduced]            # we have to recompute numpool now:            network_num_pool_per_axis, pool_op_kernel_sizes, conv_kernel_sizes, new_shp, \            shape_must_be_divisible_by = get_pool_and_conv_props_poolLateV2(new_shp,                                                                            self.unet_featuremap_min_edge_length,                                                                            self.unet_max_numpool,                                                                            current_spacing)            here = Generic_UNet.compute_approx_vram_consumption(new_shp, network_num_pool_per_axis,                                                                self.unet_base_num_features,                                                                self.unet_max_num_filters, num_modalities,                                                                num_classes, pool_op_kernel_sizes,                                                                conv_per_stage=self.conv_per_stage)            # print(new_shp)        input_patch_size = new_shp        batch_size = Generic_UNet.DEFAULT_BATCH_SIZE_3D  # This is what works with 128**3        batch_size = int(np.floor(max(ref / here, 1) * batch_size))        # check if batch size is too large        max_batch_size = np.round(self.batch_size_covers_max_percent_of_dataset * dataset_num_voxels /                                  np.prod(input_patch_size, dtype=np.int64)).astype(int)        max_batch_size = max(max_batch_size, self.unet_min_batch_size)        batch_size = max(1, min(batch_size, max_batch_size))        do_dummy_2D_data_aug = (max(input_patch_size) / input_patch_size[            0]) > self.anisotropy_threshold        plan = {            'batch_size': batch_size,            'num_pool_per_axis': network_num_pool_per_axis,            'patch_size': input_patch_size,            'median_patient_size_in_voxels': new_median_shape,            'current_spacing': current_spacing,            'original_spacing': original_spacing,            'do_dummy_2D_data_aug': do_dummy_2D_data_aug,            'pool_op_kernel_sizes': pool_op_kernel_sizes,            'conv_kernel_sizes': conv_kernel_sizes,        }        return plan    def plan_experiment(self):        use_nonzero_mask_for_normalization = self.determine_whether_to_use_mask_for_norm()        print("Are we using the nonzero mask for normalization?", use_nonzero_mask_for_normalization)        spacings = self.dataset_properties['all_spacings']        sizes = self.dataset_properties['all_sizes']        all_classes = self.dataset_properties['all_classes']        modalities = self.dataset_properties['modalities']        num_modalities = len(list(modalities.keys()))        target_spacing = self.get_target_spacing()        new_shapes = [np.array(i) / target_spacing * np.array(j) for i, j in zip(spacings, sizes)]        max_spacing_axis = np.argmax(target_spacing)        remaining_axes = [i for i in list(range(3)) if i != max_spacing_axis]        self.transpose_forward = [max_spacing_axis] + remaining_axes        self.transpose_backward = [np.argwhere(np.array(self.transpose_forward) == i)[0][0] for i in range(3)]        # we base our calculations on the median shape of the datasets        median_shape = np.median(np.vstack(new_shapes), 0)        print("the median shape of the dataset is ", median_shape)        max_shape = np.max(np.vstack(new_shapes), 0)        print("the max shape in the dataset is ", max_shape)        min_shape = np.min(np.vstack(new_shapes), 0)        print("the min shape in the dataset is ", min_shape)        print("we don't want feature maps smaller than ", self.unet_featuremap_min_edge_length, " in the bottleneck")        # how many stages will the image pyramid have?        self.plans_per_stage = list()        target_spacing_transposed = np.array(target_spacing)[self.transpose_forward]        median_shape_transposed = np.array(median_shape)[self.transpose_forward]        print("the transposed median shape of the dataset is ", median_shape_transposed)        print("generating configuration for 3d_fullres")        self.plans_per_stage.append(self.get_properties_for_stage(target_spacing_transposed, target_spacing_transposed,                                                                  median_shape_transposed,                                                                  len(self.list_of_cropped_npz_files),                                                                  num_modalities, len(all_classes) + 1))        # thanks Zakiyi (https://github.com/MIC-DKFZ/nnUNet/issues/61) for spotting this bug :-)        # if np.prod(self.plans_per_stage[-1]['median_patient_size_in_voxels'], dtype=np.int64) / \        #        architecture_input_voxels < HOW_MUCH_OF_A_PATIENT_MUST_THE_NETWORK_SEE_AT_STAGE0:        architecture_input_voxels_here = np.prod(self.plans_per_stage[-1]['patch_size'], dtype=np.int64)        if np.prod(median_shape) / architecture_input_voxels_here < \                self.how_much_of_a_patient_must_the_network_see_at_stage0:            more = False        else:            more = True        if more:            print("generating configuration for 3d_lowres")            # if we are doing more than one stage then we want the lowest stage to have exactly            # HOW_MUCH_OF_A_PATIENT_MUST_THE_NETWORK_SEE_AT_STAGE0 (this is 4 by default so the number of voxels in the            # median shape of the lowest stage must be 4 times as much as the network can process at once (128x128x128 by            # default). Problem is that we are downsampling higher resolution axes before we start downsampling the            # out-of-plane axis. We could probably/maybe do this analytically but I am lazy, so here            # we do it the dumb way            lowres_stage_spacing = deepcopy(target_spacing)            num_voxels = np.prod(median_shape, dtype=np.float64)            while num_voxels > self.how_much_of_a_patient_must_the_network_see_at_stage0 * architecture_input_voxels_here:                max_spacing = max(lowres_stage_spacing)                if np.any((max_spacing / lowres_stage_spacing) > 2):                    lowres_stage_spacing[(max_spacing / lowres_stage_spacing) > 2] \                        *= 1.01                else:                    lowres_stage_spacing *= 1.01                num_voxels = np.prod(target_spacing / lowres_stage_spacing * median_shape, dtype=np.float64)                lowres_stage_spacing_transposed = np.array(lowres_stage_spacing)[self.transpose_forward]                new = self.get_properties_for_stage(lowres_stage_spacing_transposed, target_spacing_transposed,                                                    median_shape_transposed,                                                    len(self.list_of_cropped_npz_files),                                                    num_modalities, len(all_classes) + 1)                architecture_input_voxels_here = np.prod(new['patch_size'], dtype=np.int64)            if 2 * np.prod(new['median_patient_size_in_voxels'], dtype=np.int64) < np.prod(                    self.plans_per_stage[0]['median_patient_size_in_voxels'], dtype=np.int64):                self.plans_per_stage.append(new)        self.plans_per_stage = self.plans_per_stage[::-1]        self.plans_per_stage = {i: self.plans_per_stage[i] for i in range(len(self.plans_per_stage))}  # convert to dict        print(self.plans_per_stage)        print("transpose forward", self.transpose_forward)        print("transpose backward", self.transpose_backward)        normalization_schemes = self.determine_normalization_scheme()        only_keep_largest_connected_component, min_size_per_class, min_region_size_per_class = None, None, None        # removed training data based postprocessing. This is deprecated        # these are independent of the stage        plans = {'num_stages': len(list(self.plans_per_stage.keys())), 'num_modalities': num_modalities,                 'modalities': modalities, 'normalization_schemes': normalization_schemes,                 'dataset_properties': self.dataset_properties, 'list_of_npz_files': self.list_of_cropped_npz_files,                 'original_spacings': spacings, 'original_sizes': sizes,                 'preprocessed_data_folder': self.preprocessed_output_folder, 'num_classes': len(all_classes),                 'all_classes': all_classes, 'base_num_features': self.unet_base_num_features,                 'use_mask_for_norm': use_nonzero_mask_for_normalization,                 'keep_only_largest_region': only_keep_largest_connected_component,                 'min_region_size_per_class': min_region_size_per_class, 'min_size_per_class': min_size_per_class,                 'transpose_forward': self.transpose_forward, 'transpose_backward': self.transpose_backward,                 'data_identifier': self.data_identifier, 'plans_per_stage': self.plans_per_stage,                 'preprocessor_name': self.preprocessor_name,                 'conv_per_stage': self.conv_per_stage,                 }        self.plans = plans        self.save_my_plans()    def determine_normalization_scheme(self):        schemes = OrderedDict()        modalities = self.dataset_properties['modalities']        num_modalities = len(list(modalities.keys()))        for i in range(num_modalities):            if modalities[i] == "CT" or modalities[i] == 'ct':                schemes[i] = "CT"            elif modalities[i] == 'noNorm':                schemes[i] = "noNorm"            else:                schemes[i] = "nonCT"        return schemes    def save_properties_of_cropped(self, case_identifier, properties):        with open(join(self.folder_with_cropped_data, "%s.pkl" % case_identifier), 'wb') as f:            pickle.dump(properties, f)    def load_properties_of_cropped(self, case_identifier):        with open(join(self.folder_with_cropped_data, "%s.pkl" % case_identifier), 'rb') as f:            properties = pickle.load(f)        return properties    def determine_whether_to_use_mask_for_norm(self):        # only use the nonzero mask for normalization of the cropping based on it resulted in a decrease in        # image size (this is an indication that the data is something like brats/isles and then we want to        # normalize in the brain region only)        modalities = self.dataset_properties['modalities']        num_modalities = len(list(modalities.keys()))        use_nonzero_mask_for_norm = OrderedDict()        for i in range(num_modalities):            if "CT" in modalities[i]:                use_nonzero_mask_for_norm[i] = False            else:                all_size_reductions = []                for k in self.dataset_properties['size_reductions'].keys():                    all_size_reductions.append(self.dataset_properties['size_reductions'][k])                if np.median(all_size_reductions) < 3 / 4.:                    print("using nonzero mask for normalization")                    use_nonzero_mask_for_norm[i] = True                else:                    print("not using nonzero mask for normalization")                    use_nonzero_mask_for_norm[i] = False        for c in self.list_of_cropped_npz_files:            case_identifier = get_case_identifier_from_npz(c)            properties = self.load_properties_of_cropped(case_identifier)            properties['use_nonzero_mask_for_norm'] = use_nonzero_mask_for_norm            self.save_properties_of_cropped(case_identifier, properties)        use_nonzero_mask_for_normalization = use_nonzero_mask_for_norm        return use_nonzero_mask_for_normalization    def write_normalization_scheme_to_patients(self):        """        This is used for test set preprocessing        :return:        """        for c in self.list_of_cropped_npz_files:            case_identifier = get_case_identifier_from_npz(c)            properties = self.load_properties_of_cropped(case_identifier)            properties['use_nonzero_mask_for_norm'] = self.plans['use_mask_for_norm']            self.save_properties_of_cropped(case_identifier, properties)    def run_preprocessing(self, num_threads):        if os.path.isdir(join(self.preprocessed_output_folder, "gt_segmentations")):            shutil.rmtree(join(self.preprocessed_output_folder, "gt_segmentations"))        shutil.copytree(join(self.folder_with_cropped_data, "gt_segmentations"),                        join(self.preprocessed_output_folder, "gt_segmentations"))        normalization_schemes = self.plans['normalization_schemes']        use_nonzero_mask_for_normalization = self.plans['use_mask_for_norm']        intensityproperties = self.plans['dataset_properties']['intensityproperties']        preprocessor_class = recursive_find_python_class([join(nnunet.__path__[0], "preprocessing")],                                                         self.preprocessor_name, current_module="nnunet.preprocessing")        assert preprocessor_class is not None        preprocessor = preprocessor_class(normalization_schemes, use_nonzero_mask_for_normalization,                                         self.transpose_forward,                                          intensityproperties)        target_spacings = [i["current_spacing"] for i in self.plans_per_stage.values()]        if self.plans['num_stages'] > 1 and not isinstance(num_threads, (list, tuple)):            num_threads = (default_num_threads, num_threads)        elif self.plans['num_stages'] == 1 and isinstance(num_threads, (list, tuple)):            num_threads = num_threads[-1]        preprocessor.run(target_spacings, self.folder_with_cropped_data, self.preprocessed_output_folder,                         self.plans['data_identifier'], num_threads)class ExperimentPlanner3D_v21(ExperimentPlanner):    """    Combines ExperimentPlannerPoolBasedOnSpacing and ExperimentPlannerTargetSpacingForAnisoAxis    We also increase the base_num_features to 32. This is solely because mixed precision training with 3D convs and    amp is A LOT faster if the number of filters is divisible by 8    """    def __init__(self, folder_with_cropped_data, preprocessed_output_folder):        super(ExperimentPlanner3D_v21, self).__init__(folder_with_cropped_data, preprocessed_output_folder)        self.data_identifier = "nnUNetData_plans_v2.1"        self.plans_fname = join(self.preprocessed_output_folder,                                "nnUNetPlansv2.1_plans_3D.pkl")        self.unet_base_num_features = 32    def get_target_spacing(self):        """        per default we use the 50th percentile=median for the target spacing. Higher spacing results in smaller data        and thus faster and easier training. Smaller spacing results in larger data and thus longer and harder training        For some datasets the median is not a good choice. Those are the datasets where the spacing is very anisotropic        (for example ACDC with (10, 1.5, 1.5)). These datasets still have examples with a spacing of 5 or 6 mm in the low        resolution axis. Choosing the median here will result in bad interpolation artifacts that can substantially        impact performance (due to the low number of slices).        """        spacings = self.dataset_properties['all_spacings']        sizes = self.dataset_properties['all_sizes']        target = np.percentile(np.vstack(spacings), self.target_spacing_percentile, 0)        # This should be used to determine the new median shape. The old implementation is not 100% correct.        # Fixed in 2.4        # sizes = [np.array(i) / target * np.array(j) for i, j in zip(spacings, sizes)]        target_size = np.percentile(np.vstack(sizes), self.target_spacing_percentile, 0)        target_size_mm = np.array(target) * np.array(target_size)        # we need to identify datasets for which a different target spacing could be beneficial. These datasets have        # the following properties:        # - one axis which much lower resolution than the others        # - the lowres axis has much less voxels than the others        # - (the size in mm of the lowres axis is also reduced)        worst_spacing_axis = np.argmax(target)        other_axes = [i for i in range(len(target)) if i != worst_spacing_axis]        other_spacings = [target[i] for i in other_axes]        other_sizes = [target_size[i] for i in other_axes]        has_aniso_spacing = target[worst_spacing_axis] > (self.anisotropy_threshold * max(other_spacings))        has_aniso_voxels = target_size[worst_spacing_axis] * self.anisotropy_threshold < min(other_sizes)        # we don't use the last one for now        #median_size_in_mm = target[target_size_mm] * RESAMPLING_SEPARATE_Z_ANISOTROPY_THRESHOLD < max(target_size_mm)        if has_aniso_spacing and has_aniso_voxels:            spacings_of_that_axis = np.vstack(spacings)[:, worst_spacing_axis]            target_spacing_of_that_axis = np.percentile(spacings_of_that_axis, 10)            # don't let the spacing of that axis get higher than the other axes            if target_spacing_of_that_axis < max(other_spacings):                target_spacing_of_that_axis = max(max(other_spacings), target_spacing_of_that_axis) + 1e-5            target[worst_spacing_axis] = target_spacing_of_that_axis        return target    def get_properties_for_stage(self, current_spacing, original_spacing, original_shape, num_cases,                                 num_modalities, num_classes):        """        ExperimentPlanner configures pooling so that we pool late. Meaning that if the number of pooling per axis is        (2, 3, 3), then the first pooling operation will always pool axes 1 and 2 and not 0, irrespective of spacing.        This can cause a larger memory footprint, so it can be beneficial to revise this.        Here we are pooling based on the spacing of the data.        """        new_median_shape = np.round(original_spacing / current_spacing * original_shape).astype(int)        dataset_num_voxels = np.prod(new_median_shape) * num_cases        # the next line is what we had before as a default. The patch size had the same aspect ratio as the median shape of a patient. We swapped t        # input_patch_size = new_median_shape        # compute how many voxels are one mm        input_patch_size = 1 / np.array(current_spacing)        # normalize voxels per mm        input_patch_size /= input_patch_size.mean()        # create an isotropic patch of size 512x512x512mm        input_patch_size *= 1 / min(input_patch_size) * 512  # to get a starting value        input_patch_size = np.round(input_patch_size).astype(int)        # clip it to the median shape of the dataset because patches larger then that make not much sense        input_patch_size = [min(i, j) for i, j in zip(input_patch_size, new_median_shape)]        network_num_pool_per_axis, pool_op_kernel_sizes, conv_kernel_sizes, new_shp, \        shape_must_be_divisible_by = get_pool_and_conv_props(current_spacing, input_patch_size,                                                             self.unet_featuremap_min_edge_length,                                                             self.unet_max_numpool)        # we compute as if we were using only 30 feature maps. We can do that because fp16 training is the standard        # now. That frees up some space. The decision to go with 32 is solely due to the speedup we get (non-multiples        # of 8 are not supported in nvidia amp)        ref = Generic_UNet.use_this_for_batch_size_computation_3D * self.unet_base_num_features / \              Generic_UNet.BASE_NUM_FEATURES_3D        here = Generic_UNet.compute_approx_vram_consumption(new_shp, network_num_pool_per_axis,                                                            self.unet_base_num_features,                                                            self.unet_max_num_filters, num_modalities,                                                            num_classes,                                                            pool_op_kernel_sizes, conv_per_stage=self.conv_per_stage)        while here > ref:            axis_to_be_reduced = np.argsort(new_shp / new_median_shape)[-1]            tmp = deepcopy(new_shp)            tmp[axis_to_be_reduced] -= shape_must_be_divisible_by[axis_to_be_reduced]            _, _, _, _, shape_must_be_divisible_by_new = \                get_pool_and_conv_props(current_spacing, tmp,                                        self.unet_featuremap_min_edge_length,                                        self.unet_max_numpool,                                        )            new_shp[axis_to_be_reduced] -= shape_must_be_divisible_by_new[axis_to_be_reduced]            # we have to recompute numpool now:            network_num_pool_per_axis, pool_op_kernel_sizes, conv_kernel_sizes, new_shp, \            shape_must_be_divisible_by = get_pool_and_conv_props(current_spacing, new_shp,                                                                 self.unet_featuremap_min_edge_length,                                                                 self.unet_max_numpool,                                                                 )            here = Generic_UNet.compute_approx_vram_consumption(new_shp, network_num_pool_per_axis,                                                                self.unet_base_num_features,                                                                self.unet_max_num_filters, num_modalities,                                                                num_classes, pool_op_kernel_sizes,                                                                conv_per_stage=self.conv_per_stage)            #print(new_shp)        #print(here, ref)        input_patch_size = new_shp        batch_size = Generic_UNet.DEFAULT_BATCH_SIZE_3D  # This is what wirks with 128**3        batch_size = int(np.floor(max(ref / here, 1) * batch_size))        # check if batch size is too large        max_batch_size = np.round(self.batch_size_covers_max_percent_of_dataset * dataset_num_voxels /                                  np.prod(input_patch_size, dtype=np.int64)).astype(int)        max_batch_size = max(max_batch_size, self.unet_min_batch_size)        batch_size = max(1, min(batch_size, max_batch_size))        do_dummy_2D_data_aug = (max(input_patch_size) / input_patch_size[            0]) > self.anisotropy_threshold        plan = {            'batch_size': batch_size,            'num_pool_per_axis': network_num_pool_per_axis,            'patch_size': input_patch_size,            'median_patient_size_in_voxels': new_median_shape,            'current_spacing': current_spacing,            'original_spacing': original_spacing,            'do_dummy_2D_data_aug': do_dummy_2D_data_aug,            'pool_op_kernel_sizes': pool_op_kernel_sizes,            'conv_kernel_sizes': conv_kernel_sizes,        }        return plan